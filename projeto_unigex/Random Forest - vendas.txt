# Importa√ß√£o das bibliotecas necess√°rias
import pandas as pd
import numpy as np
import joblib
import json
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.datasets import make_regression # Usado para criar dados de exemplo

def executar_pipeline_treinamento():
    """
    Fun√ß√£o principal que executa o pipeline completo:
    1. Carga e divis√£o dos dados
    2. Treinamento do modelo
    3. Avalia√ß√£o de performance
    4. An√°lise de import√¢ncia das vari√°veis
    5. Salvamento do modelo e m√©tricas
    """
    
    # --- 1. PREPARA√á√ÉO E DIVIS√ÉO DOS DADOS ---
    print("Iniciando Tarefa 1: Prepara√ß√£o e Divis√£o dos Dados...")
    
    # NOTA: Esta se√ß√£o cria dados de exemplo para que o script seja execut√°vel.
    # SUBSTITUA ESTA PARTE pelo carregamento dos seus dados reais.
    # Exemplo para carregar seus dados:
    # dados_processados = joblib.load('padronizado_vendas.z')
    # X = pd.DataFrame(dados_processados['X_train_standard']) # Adapte conforme a estrutura do seu arquivo
    # y = pd.Series(dados_processados['y_train'])

    X, y = make_regression(n_samples=1000, n_features=15, n_informative=10, noise=25, random_state=42)
    feature_names = [f'variavel_{i+1}' for i in range(X.shape[1])]
    X = pd.DataFrame(X, columns=feature_names)
    
    # Dividir os dados em conjuntos de treino (80%) e teste (20%)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    print(f"Dados divididos: {X_train.shape[0]} amostras de treino e {X_test.shape[0]} amostras de teste.")
    print("-" * 50)

    # --- 2. TREINAMENTO DO MODELO ---
    print("Iniciando Tarefa 2: Treinamento do Modelo RandomForestRegressor...")
    
    # Instanciar o modelo com par√¢metros b√°sicos
    rf_model = RandomForestRegressor(
        n_estimators=150,      # N√∫mero de √°rvores na floresta (ajust√°vel)
        max_depth=20,          # Profundidade m√°xima de cada √°rvore (ajust√°vel)
        random_state=42,       # Garante a reprodutibilidade dos resultados
        n_jobs=-1              # Utiliza todos os processadores dispon√≠veis para acelerar
    )
    
    # Treinar o modelo com os dados de treino
    rf_model.fit(X_train, y_train)
    print("Modelo treinado com sucesso.")
    print("-" * 50)

    # --- 3. AVALIA√á√ÉO DE DESEMPENHO ---
    print("Iniciando Tarefa 3: Avalia√ß√£o de Desempenho no Conjunto de Teste...")
    
    # Fazer previs√µes no conjunto de teste
    y_pred = rf_model.predict(X_test)
    
    # Calcular as m√©tricas
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse) # RMSE √© a raiz quadrada do MSE
    r2 = r2_score(y_test, y_pred)
    
    print(f"  -> Mean Absolute Error (MAE): {mae:.4f}")
    print(f"  -> Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"  -> R-quadrado (R¬≤): {r2:.4f}")
    print("-" * 50)

    # --- 4. AN√ÅLISE DA IMPORT√ÇNCIA DAS VARI√ÅVEIS ---
    print("Iniciando Tarefa 4: An√°lise da Import√¢ncia das Vari√°veis...")
    
    importances = rf_model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Variavel': X_train.columns,
        'Importancia': importances
    }).sort_values(by='Importancia', ascending=False)
    
    print("As 5 vari√°veis mais importantes segundo o modelo:")
    print(feature_importance_df.head())
    print("-" * 50)
    
    # --- 5. SALVAR O MODELO E AS M√âTRICAS ---
    print("Iniciando Tarefa 5: Salvando o Modelo e as M√©tricas...")
    
    # Salvar o modelo treinado
    nome_arquivo_modelo = 'modelo_random_forest_vendas.joblib'
    joblib.dump(rf_model, nome_arquivo_modelo)
    print(f"Modelo salvo com sucesso como '{nome_arquivo_modelo}'")
    
    # Estruturar e salvar as m√©tricas em um arquivo JSON
    metricas = {
        'MAE': mae,
        'RMSE': rmse,
        'R2': r2
    }
    nome_arquivo_metricas = 'metricas_modelo_rf.json'
    with open(nome_arquivo_metricas, 'w') as f:
        json.dump(metricas, f, indent=4)
    print(f"M√©tricas salvas com sucesso como '{nome_arquivo_metricas}'")
    print("-" * 50)

# Bloco de execu√ß√£o principal
if __name__ == "__main__":
    executar_pipeline_treinamento()

Principais Conclus√µes
Modelo com Bom Desempenho Preditivo ‚úÖ

O modelo atingiu um R-quadrado (R 
2
 ) de aproximadamente 0.81 (0.8065). Isso significa que ele √© capaz de explicar cerca de 81% da varia√ß√£o nos dados, o que √© considerado um resultado forte para muitos problemas de regress√£o. Ele n√£o est√° apenas "chutando", mas sim capturando padr√µes reais.
Identifica√ß√£o das Vari√°veis Mais Relevantes üìä

A an√°lise de import√¢ncia revelou quais vari√°veis (variavel_6, variavel_2, variavel_3, etc.) s√£o as mais influentes para as previs√µes do modelo. Essa √© uma conclus√£o valiosa, pois em um cen√°rio real, isso direcionaria o foco para os fatores que mais importam para o neg√≥cio.
Cria√ß√£o de Ativos Reutiliz√°veis üíæ

O c√≥digo n√£o apenas executa uma an√°lise, ele produz dois arquivos finais essenciais:
modelo_random_forest_vendas.joblib: O modelo treinado, pronto para ser carregado e fazer previs√µes em novos dados sem a necessidade de um novo treinamento.
metricas_modelo_rf.json: Um registro permanente do desempenho, crucial para comparar este modelo com futuras vers√µes ou outros algoritmos.
Em resumo, o script executa um ciclo completo de ci√™ncia de dados, resultando em um modelo preditivo eficaz, interpret√°vel e pronto para uso.
